{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5006b09-1a04-4cc6-9ef3-4e92cdf48cdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "875131f6-e059-4734-89df-11a270b05e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Press ENTER to see the data for 2017-08-10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumption        1351.491\n",
      "YouTube             100.274\n",
      "Netflix               71.16\n",
      "YouTube+Netflix     171.434\n",
      "Year                   2017\n",
      "Month                     8\n",
      "Weekday Name       Thursday\n",
      "Name: 2017-08-10 00:00:00, dtype: object\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Press ENTER to see the data slice from 2014-01-20 to 2014-01-22 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Consumption  YouTube  Netflix  YouTube+Netflix  Year  Month  \\\n",
      "Date                                                                      \n",
      "2014-01-20     1590.687   78.647    6.371           85.018  2014      1   \n",
      "2014-01-21     1624.806   15.643    5.835           21.478  2014      1   \n",
      "2014-01-22     1625.155   60.259   11.992           72.251  2014      1   \n",
      "\n",
      "           Weekday Name  \n",
      "Date                     \n",
      "2014-01-20       Monday  \n",
      "2014-01-21      Tuesday  \n",
      "2014-01-22    Wednesday  \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Press ENTER to see the data slice for 2012-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Consumption  YouTube  Netflix  YouTube+Netflix  Year  Month  \\\n",
      "Date                                                                      \n",
      "2012-02-01     1511.866  199.607   43.502          243.109  2012      2   \n",
      "2012-02-02     1563.407   73.469   44.675          118.144  2012      2   \n",
      "2012-02-03     1563.631   36.352   46.510           82.862  2012      2   \n",
      "2012-02-04     1372.614   20.551   45.225           65.776  2012      2   \n",
      "2012-02-05     1279.432   55.522   54.572          110.094  2012      2   \n",
      "2012-02-06     1574.766   34.896   55.389           90.285  2012      2   \n",
      "2012-02-07     1615.078  100.312   19.867          120.179  2012      2   \n",
      "2012-02-08     1613.774   93.763   36.930          130.693  2012      2   \n",
      "2012-02-09     1591.532  132.219   19.042          151.261  2012      2   \n",
      "2012-02-10     1581.287   52.122   34.873           86.995  2012      2   \n",
      "2012-02-11     1377.404   32.375   44.629           77.004  2012      2   \n",
      "2012-02-12     1264.254   62.659   45.176          107.835  2012      2   \n",
      "2012-02-13     1561.987   25.984   11.287           37.271  2012      2   \n",
      "2012-02-14     1550.366  146.495    9.610          156.105  2012      2   \n",
      "2012-02-15     1476.037  413.367   18.877          432.244  2012      2   \n",
      "2012-02-16     1504.119  130.247   38.176          168.423  2012      2   \n",
      "2012-02-17     1438.857  196.515   17.328          213.843  2012      2   \n",
      "2012-02-18     1236.069  237.889   26.248          264.137  2012      2   \n",
      "2012-02-19     1107.431  272.655   30.382          303.037  2012      2   \n",
      "2012-02-20     1401.873  160.315   53.794          214.109  2012      2   \n",
      "2012-02-21     1434.533  281.909   57.984          339.893  2012      2   \n",
      "2012-02-22     1453.507  287.635   74.904          362.539  2012      2   \n",
      "2012-02-23     1427.402  353.510   18.927          372.437  2012      2   \n",
      "2012-02-24     1373.800  382.777   29.281          412.058  2012      2   \n",
      "2012-02-25     1133.184  302.102   42.667          344.769  2012      2   \n",
      "2012-02-26     1086.743   95.234   37.214          132.448  2012      2   \n",
      "2012-02-27     1436.095   86.956   43.099          130.055  2012      2   \n",
      "2012-02-28     1408.211  231.923   16.190          248.113  2012      2   \n",
      "2012-02-29     1434.062   77.024   30.360          107.384  2012      2   \n",
      "\n",
      "           Weekday Name  \n",
      "Date                     \n",
      "2012-02-01    Wednesday  \n",
      "2012-02-02     Thursday  \n",
      "2012-02-03       Friday  \n",
      "2012-02-04     Saturday  \n",
      "2012-02-05       Sunday  \n",
      "2012-02-06       Monday  \n",
      "2012-02-07      Tuesday  \n",
      "2012-02-08    Wednesday  \n",
      "2012-02-09     Thursday  \n",
      "2012-02-10       Friday  \n",
      "2012-02-11     Saturday  \n",
      "2012-02-12       Sunday  \n",
      "2012-02-13       Monday  \n",
      "2012-02-14      Tuesday  \n",
      "2012-02-15    Wednesday  \n",
      "2012-02-16     Thursday  \n",
      "2012-02-17       Friday  \n",
      "2012-02-18     Saturday  \n",
      "2012-02-19       Sunday  \n",
      "2012-02-20       Monday  \n",
      "2012-02-21      Tuesday  \n",
      "2012-02-22    Wednesday  \n",
      "2012-02-23     Thursday  \n",
      "2012-02-24       Friday  \n",
      "2012-02-25     Saturday  \n",
      "2012-02-26       Sunday  \n",
      "2012-02-27       Monday  \n",
      "2012-02-28      Tuesday  \n",
      "2012-02-29    Wednesday  \n"
     ]
    }
   ],
   "source": [
    "# consolidate the above steps into a single line using the index_col and parse_dates parameters of the read_csv() function\n",
    "opsd_daily = pd.read_csv('netTraffic.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "# add some additional columns to our data\n",
    "# Add columns with year, month, and weekday name\n",
    "opsd_daily['Year'] = opsd_daily.index.year\n",
    "opsd_daily['Month'] = opsd_daily.index.month\n",
    "# required to 'pull' the day name (ex. Monday, Tuesday, happy days...)\n",
    "opsd_daily['Weekday Name'] = opsd_daily.index.day_name()\n",
    "\n",
    "# select data for a single day using a string such as '2017-08-10'\n",
    "input(\"\\nPress ENTER to see the data for 2017-08-10\")\n",
    "print(opsd_daily.loc['2017-08-10'])\n",
    "\n",
    "# select a slice of days, '2014-01-20':'2014-01-22'\n",
    "# Note that the slice is inclusive of both endpoints\n",
    "input(\"\\nPress ENTER to see the data slice from 2014-01-20 to 2014-01-22\")\n",
    "print(opsd_daily.loc['2014-01-20':'2014-01-22'])\n",
    "\n",
    "# partial-string indexing select all date/times which partially match a given string\n",
    "# select the entire year 2006 with opsd_daily.loc['2006']\n",
    "# select the entire month of February 2012 with opsd_daily.loc['2012-02']\n",
    "input(\"\\nPress ENTER to see the data slice for 2012-02\")\n",
    "print(opsd_daily.loc['2012-02'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607fd9a9-41b5-444d-b822-726cddfbd85b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
